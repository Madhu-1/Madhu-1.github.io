<!DOCTYPE html>
<html>
  <head>
    <title>DR failover and failback for RBD Async mirroring with minikube – Madhu Rajanna – Senior Software Engineer at RedHat</title>

        <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="This doc assumes that you already set up the rbd mirroring between two clusters.

" />
    <meta property="og:description" content="This doc assumes that you already set up the rbd mirroring between two clusters.

" />
    
    <meta name="author" content="Madhu Rajanna" />

    
    <meta property="og:title" content="DR failover and failback for RBD Async mirroring with minikube" />
    <meta property="twitter:title" content="DR failover and failback for RBD Async mirroring with minikube" />
    
    <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>DR failover and failback for RBD Async mirroring with minikube | Madhu Rajanna</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="DR failover and failback for RBD Async mirroring with minikube" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This doc assumes that you already set up the rbd mirroring between two clusters." />
<meta property="og:description" content="This doc assumes that you already set up the rbd mirroring between two clusters." />
<link rel="canonical" href="https://mrajanna.com/rbd-async-mirroring-dr-with-rook/" />
<meta property="og:url" content="https://mrajanna.com/rbd-async-mirroring-dr-with-rook/" />
<meta property="og:site_name" content="Madhu Rajanna" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-05-04T00:00:00+05:30" />
<script type="application/ld+json">
{"@type":"BlogPosting","url":"https://mrajanna.com/rbd-async-mirroring-dr-with-rook/","headline":"DR failover and failback for RBD Async mirroring with minikube","dateModified":"2021-05-04T00:00:00+05:30","datePublished":"2021-05-04T00:00:00+05:30","mainEntityOfPage":{"@type":"WebPage","@id":"https://mrajanna.com/rbd-async-mirroring-dr-with-rook/"},"description":"This doc assumes that you already set up the rbd mirroring between two clusters.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<meta name="google-site-verification" content="qrFYIlFxt1yD_oRmFPV2ZpEOYn46EXVxnRpg2HhMaUU" />
  <link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://mrajanna.com/feed.xml" title="Madhu Rajanna" />
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'qrFYIlFxt1yD_oRmFPV2ZpEOYn46EXVxnRpg2HhMaUU', 'auto');
		ga('send', 'pageview', {
		  'page': '/rbd-async-mirroring-dr-with-rook/',
		  'title': 'DR failover and failback for RBD Async mirroring with minikube'
		});
	</script>
	<!-- End Google Analytics -->

</head>


    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="alternate" type="application/rss+xml" title="Madhu Rajanna - Senior Software Engineer at RedHat" href="/feed.xml" />

    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  </head>

  <body>
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="/" class="site-avatar"><img src="https://raw.githubusercontent.com/Madhu-1/Madhu-1.github.io/master/images/Madhu.jpeg" /></a>
          <nav>
            <a href="/">Blog</a>
            <a href="/about">about</a>
            <a href="/resume">Resume</a>
          </nav>
          <br />
          <br />
          <br />
          <br />
          <br />
          <br />
          <br />
          <div class="site-info">
            <h1 class="site-name"><strong><a href="/">Madhu Rajanna</a></strong></h1>
          </div>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <article class="post">
  <h1>DR failover and failback for RBD Async mirroring with minikube</h1>

  <div class="entry">
    <p>This doc assumes that you already set up the rbd mirroring between two clusters.</p>

<p>Please refer to <a href="../setup-rbd-async-mirroring-with-rook">doc</a> on how
to setup RBD mirroring.</p>

<h2 id="set-up-initial-dr-components">Set up initial DR components</h2>

<p>we need to Enable two new sidecar deployment in the RBD provisioner pods which
will help in achieving rbd mirroring</p>

<ul>
  <li>
    <p>OMAP Regenerator -&gt; This is a cephcsi component that regenerates the
required OMAP data for cephcsi to perform CSI operations after failover.</p>
  </li>
  <li>
    <p>Volume Replication operator -&gt; Volume replication operator which exposes
Replication CRD to perform the RBD async operations like enable and disable mirroring,
promote, demote, force promote, and resync. Refer <a href="https://github.com/csi-addons/volume-replication-operator">operator</a> for more details about it.</p>
  </li>
</ul>

<h3 id="enable-dr-components">Enable DR components</h3>

<h4 id="upgrade-to-rook-v160">Upgrade to Rook v1.6.0+</h4>

<p>Rook <a href="https://github.com/rook/rook/releases/tag/v1.6.0">v1.6.0</a> comes with the
new volume replication support and also cephcsi v3.3.0, Install/Upgrade to Rook
v1.6.0 or higher versions.</p>

<h4 id="re-apply-the-commonyaml-and-crdsyaml">Re-apply the common.yaml and crds.yaml</h4>

<pre><code class="language-bash=">kubectl apply -f crds.yaml common.yaml
</code></pre>

<blockquote>
  <p>Once we reapply/create the crds.yaml we should see two new CRD’s related to
volume replication</p>
</blockquote>

<pre><code class="language-bash=">$ kubectl get crd |grep volumereplication
volumereplicationclasses.replication.storage.openshift.io   2021-04-28T05:57:57Z
volumereplications.replication.storage.openshift.io         2021-04-28T05:57:57Z
</code></pre>

<p>As we need to provide Edit <code class="language-plaintext highlighter-rouge">rook-ceph-operator-config</code> configmap and add below
two configurations to the list</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">v1</span>
<span class="na">data</span><span class="pi">:</span>
  <span class="na">CSI_ENABLE_OMAP_GENERATOR</span><span class="pi">:</span> <span class="s2">"</span><span class="s">true"</span>
  <span class="na">CSI_ENABLE_VOLUME_REPLICATION</span><span class="pi">:</span> <span class="s2">"</span><span class="s">true"</span>
</code></pre></div></div>

<pre><code class="language-bash=">$kubectl edit cm rook-ceph-operator-config  -nrook-ceph
</code></pre>

<blockquote>
  <p>Once you edit and save the configmap you will see that CSI pods are getting
recreated, just wait until you see 8 containers in <code class="language-plaintext highlighter-rouge">csi-rbdplugin-provisioner-xxx</code>
pod.</p>
</blockquote>

<pre><code class="language-bash=">kubectl get po -nrook-ceph
NAME                                            READY   STATUS      RESTARTS   AGE
csi-cephfsplugin-bkgkt                          3/3     Running     0          5d23h
csi-cephfsplugin-provisioner-6544c5b576-ndf58   6/6     Running     0          5d23h
csi-rbdplugin-provisioner-7465df5764-5g8mj      8/8     Running     0          6m7s
csi-rbdplugin-vpq4k                             3/3     Running     0          5d23h
rook-ceph-mgr-a-54bbfb54b9-pg827                1/1     Running     0          6d
rook-ceph-mon-a-79dfbdcdb6-qwssl                1/1     Running     0          6d
rook-ceph-operator-54cf7487d4-gdp5s             1/1     Running     0          6d
rook-ceph-osd-0-b99c76b7b-6cbnk                 1/1     Running     0          6d
rook-ceph-osd-prepare-minicluster2-57552        0/1     Completed   0          6d
rook-ceph-rbd-mirror-a-d449c66db-2c4hr          1/1     Running     0          5d23h
rook-ceph-tools-78cdfd976c-nm2jx                1/1     Running     0          6d
</code></pre>

<pre><code class="language-bash=">kubectl logs po/csi-rbdplugin-provisioner-7465df5764-5g8mj -nrook-ceph
error: a container name must be specified for pod csi-rbdplugin-provisioner-7465df5764-5g8mj, choose one of: [csi-provisioner csi-resizer csi-attacher csi-snapshotter csi-omap-generator volume-replication csi-rbdplugin liveness-prometheus]
</code></pre>

<blockquote>
  <p>In the above logs we can see that <code class="language-plaintext highlighter-rouge">csi-omap-generator</code> and
<code class="language-plaintext highlighter-rouge">volume-replication</code> containers got created in
<code class="language-plaintext highlighter-rouge">csi-rbdplugin-provisioner-xxx</code> pods.</p>
</blockquote>

<p><strong>Note</strong> The above steps need to be done on both clusters.</p>

<p>Now the initial bootstrapping is completed.</p>

<h2 id="provision-storage-on-cluster1">Provision storage on cluster1</h2>

<p>Create a <code class="language-plaintext highlighter-rouge">storageclass</code> and <code class="language-plaintext highlighter-rouge">PVC</code></p>

<h3 id="create-storageclass-on-cluster1">Create storageclass on cluster1</h3>

<pre><code class="language-bash=">$cat &lt;&lt;EOF | kubectl --context=cluster1 apply -f -
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
   name: rook-ceph-block
provisioner: rook-ceph.rbd.csi.ceph.com
parameters:
    clusterID: rook-ceph
    pool: replicapool
    imageFormat: "2"
    imageFeatures: layering
    csi.storage.k8s.io/provisioner-secret-name: rook-csi-rbd-provisioner
    csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
    csi.storage.k8s.io/controller-expand-secret-name: rook-csi-rbd-provisioner
    csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
    csi.storage.k8s.io/node-stage-secret-name: rook-csi-rbd-node
    csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
    csi.storage.k8s.io/fstype: ext4
reclaimPolicy: Retain
EOF
storageclass.storage.k8s.io/rook-ceph-block created
</code></pre>

<blockquote>
  <p>Create a storageclass with <code class="language-plaintext highlighter-rouge">Retain</code> <code class="language-plaintext highlighter-rouge">reclaimPolicy</code> so that we can use static binding for
DR.</p>
</blockquote>

<h3 id="create-persistentvolumeclaim-on-cluster1">Create PersistentVolumeClaim on cluster1</h3>

<pre><code class="language-bash=">$cat &lt;&lt;EOF | kubectl --context=cluster1 apply -f -
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: rbd-pvc
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
  storageClassName: rook-ceph-block
EOF
</code></pre>

<p>Check PVC is in bound state</p>

<pre><code class="language-bash=">$kubectl get pvc --context=cluster1
NAME      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE
rbd-pvc   Bound    pvc-57cfca36-cb76-4d79-b258-a107bc5c4d15   1Gi        RWO            rook-ceph-block   44s
</code></pre>

<h3 id="create-volume-replication-class-on-cluster1">Create Volume Replication class on cluster1</h3>

<pre><code class="language-bash=">$cat &lt;&lt;EOF | kubectl --context=cluster1 apply -f -
apiVersion: replication.storage.openshift.io/v1alpha1
kind: VolumeReplicationClass
metadata:
  name: rbd-volumereplicationclass
spec:
  provisioner: rook-ceph.rbd.csi.ceph.com
  parameters:
    mirroringMode: snapshot
    replication.storage.openshift.io/replication-secret-name: rook-csi-rbd-provisioner
    replication.storage.openshift.io/replication-secret-namespace: rook-ceph
EOF
</code></pre>

<blockquote>
  <p>The volume replication class holds the storage admin information required
for the volume replication operator.</p>
</blockquote>

<h3 id="create-volume-replication-for-pvc-on-cluster1">Create Volume Replication for PVC on cluster1</h3>

<pre><code class="language-bash=">$cat &lt;&lt;EOF | kubectl --context=cluster1 apply -f -
apiVersion: replication.storage.openshift.io/v1alpha1
kind: VolumeReplication
metadata:
  name: pvc-volumereplication2
spec:
  volumeReplicationClass: rbd-volumereplicationclass
  replicationState: primary
  dataSource:
    apiGroup: ""
    kind: PersistentVolumeClaim
    name: rbd-pvc # Name of the PVC to which mirroring to be enabled.
EOF
</code></pre>

<blockquote>
  <p><code class="language-plaintext highlighter-rouge">replicationState</code> is the state of the volume being referenced.
  Possible values are <code class="language-plaintext highlighter-rouge">primary</code>, <code class="language-plaintext highlighter-rouge">secondary</code>, and <code class="language-plaintext highlighter-rouge">resync</code>.</p>
  <ul>
    <li><code class="language-plaintext highlighter-rouge">primary</code> denotes that the volume is primary</li>
    <li><code class="language-plaintext highlighter-rouge">secondary</code> denotes that the volume is secondary</li>
    <li><code class="language-plaintext highlighter-rouge">resync</code> denotes that the volume needs to be resynced</li>
  </ul>
</blockquote>

<blockquote>
  <p>Note the <code class="language-plaintext highlighter-rouge">VolumeReplication</code> is a namespace scoped object it should be in the namespace as of PVC.</p>
</blockquote>

<p>Check VolumeReplication CR status</p>

<pre><code class="language-bash=">$ kubectl get volumereplication pvc-volumereplication -oyaml
...
spec:
  dataSource:
    apiGroup: ""
    kind: PersistentVolumeClaim
    name: rbd-pvc
  replicationState: primary
  volumeReplicationClass: rbd-volumereplicationclass
status:
  conditions:
  - lastTransitionTime: "2021-05-04T07:39:00Z"
    message: ""
    observedGeneration: 1
    reason: Promoted
    status: "True"
    type: Completed
  - lastTransitionTime: "2021-05-04T07:39:00Z"
    message: ""
    observedGeneration: 1
    reason: Healthy
    status: "False"
    type: Degraded
  - lastTransitionTime: "2021-05-04T07:39:00Z"
    message: ""
    observedGeneration: 1
    reason: NotResyncing
    status: "False"
    type: Resyncing
  lastCompletionTime: "2021-05-04T07:39:00Z"
  lastStartTime: "2021-05-04T07:38:59Z"
  message: volume is marked primary
  observedGeneration: 1
  state: Primary
</code></pre>

<p>Run commands on toolbox pod on cluster1 to check to mirror is enabled on ceph block pool</p>

<pre><code class="language-bash=">$kubectl get po --context=cluster1 -nrook-ceph -l  app=rook-ceph-tools
NAME                               READY   STATUS    RESTARTS   AGE
rook-ceph-tools-78cdfd976c-jrhjm   1/1     Running   0          3m53s
</code></pre>

<p>Verify that mirroring enabled on the image</p>

<pre><code class="language-bash=">$kubectl exec --context=cluster1 -nrook-ceph rook-ceph-tools-78cdfd976c-jrhjm -- rbd info csi-vol-1b82d349-2d5a-11eb-b8d5-0242ac110004 --pool=replicapool
rbd image 'csi-vol-1b82d349-2d5a-11eb-b8d5-0242ac110004':
    size 1 GiB in 256 objects
    order 22 (4 MiB objects)
    snapshot_count: 1
    id: 13a672b41f5f
    block_name_prefix: rbd_data.13a672b41f5f
    format: 2
    features: layering
    op_features:
    flags:
    create_timestamp: Mon Nov 23 07:04:21 2020
    access_timestamp: Mon Nov 23 07:04:21 2020
    modify_timestamp: Mon Nov 23 07:04:21 2020
    mirroring state: enabled
    mirroring mode: snapshot
    mirroring global id: 7da10ec2-aa67-4b05-86f0-487b4fa9fdbb
    mirroring primary: true
</code></pre>

<blockquote>
  <p>You can get the RBD image name from the PV object.</p>
</blockquote>

<h4 id="verify-that-the-image-is-mirrored-on-the-secondary-cluster">Verify that the image is mirrored on the secondary cluster</h4>

<p>Run commands on toolbox pod on cluster2</p>

<pre><code class="language-bash=">$kubectl get po --context=cluster2 -nrook-ceph -l  app=rook-ceph-tools
NAME                               READY   STATUS    RESTARTS   AGE
rook-ceph-tools-78cdfd976c-2566m   1/1     Running   0          3m53s
</code></pre>

<pre><code class="language-bash=">$kubectl exec --context=cluster2 -nrook-ceph rook-ceph-tools-78cdfd976c-2566m -- rbd info csi-vol-1b82d349-2d5a-11eb-b8d5-0242ac110004 --pool=replicapool
rbd image 'csi-vol-1b82d349-2d5a-11eb-b8d5-0242ac110004':
    size 1 GiB in 256 objects
    order 22 (4 MiB objects)
    snapshot_count: 1
    id: 12a55edc8361
    block_name_prefix: rbd_data.12a55edc8361
    format: 2
    features: layering, non-primary
    op_features:
    flags:
    create_timestamp: Mon Nov 23 07:12:33 2020
    access_timestamp: Mon Nov 23 07:12:33 2020
    modify_timestamp: Mon Nov 23 07:12:33 2020
    mirroring state: enabled
    mirroring mode: snapshot
    mirroring global id: 7da10ec2-aa67-4b05-86f0-487b4fa9fdbb
    mirroring primary: false
</code></pre>

<h3 id="take-a-backup-of-pvc-and-pv-object-on-cluster1">Take a backup of PVC and PV object on cluster1</h3>

<pre><code class="language-bash=">kubectl get pvc rbd-pvc -oyaml &gt;pvc-bkp.yaml
</code></pre>

<pre><code class="language-bash=">kubectl get pv/pvc-0b93de3a-3946-4909-a189-f44dba0abc76 -oyaml &gt;pv_bkp.yaml
</code></pre>

<h4 id="remove-the-claimref-on-the-backed-up-pv-objects-in--yaml-files">Remove the claimRef on the backed up PV objects in  yaml files</h4>

<p>sample claimRef in PV object</p>

<pre><code class="language-yaml=">apiVersion: v1
kind: PersistentVolume
metadata:
  ...
  name: pvc-0b93de3a-3946-4909-a189-f44dba0abc76
  resourceVersion: "2516"
  selfLink: /api/v1/persistentvolumes/pvc-0b93de3a-3946-4909-a189-f44dba0abc76
  uid: 0b1a1560-2c0b-4906-8059-d6be95954bc0
spec:
  claimRef:
    apiVersion: v1
    kind: PersistentVolumeClaim
    name: rbd-pvc
    namespace: default
    resourceVersion: "2512"
    uid: 0b93de3a-3946-4909-a189-f44dba0abc76
 ...
</code></pre>

<blockquote>
  <p>Remove the claimRef in all PV backup’s</p>
</blockquote>

<pre><code class="language-bash=">vi pv_bkp.yaml
</code></pre>

<h2 id="planned-storage-migration">Planned Storage Migration</h2>

<h3 id="failover">Failover</h3>

<p>Follow the Below steps for planned migration when you want to move the workload from one cluster to another cluster</p>

<ul>
  <li>Scale down all the application pods which are using the mirrored PVC</li>
  <li>Take a back up of PVC and PV object from the cluster1
    <ul>
      <li>This can be done using some backup tools like velero also</li>
    </ul>
  </li>
  <li>update replicationState to secondary in VolumeReplication CR at Primary Site. When the operator sees this change, it will pass the information down to the driver via GRPC request to mark the dataSource as secondary.</li>
  <li>If you are manually recreating the PVC and PV on the secondary cluster. remove the claimRef section in the PV objects.</li>
  <li>Recreate the storageclass, PVC, and PV objects on the cluster2
    <ul>
      <li>As you are creating the static binding between PVC and PV, a new PV won’t be created here, the PVC will get bind to the existing PV.</li>
    </ul>
  </li>
  <li>Create the VolumeReplicationClass on the cluster2</li>
  <li>Create the VolumeReplications for all the PVC’s for which mirroring is enabled
    <ul>
      <li><code class="language-plaintext highlighter-rouge">replicationState</code> should be <code class="language-plaintext highlighter-rouge">primary</code> for all the PVC’s on the cluster1</li>
    </ul>
  </li>
  <li>Check whether the image is primary on cluster2 by looking at toolbox or VolumeReplication CR status</li>
  <li>Once the Image is marked as Primary create the application to use the PVC
In the case of planned migration,</li>
</ul>

<h4 id="failback">Failback</h4>

<p>Once the planned work is done and you want to failback, follow the above Failover steps again. the only difference, in this case, is we don’t need to recreate anything we just need to change <code class="language-plaintext highlighter-rouge">replicationState</code> from <code class="language-plaintext highlighter-rouge">secondary</code> to <code class="language-plaintext highlighter-rouge">primary</code> in current cluster1.</p>

<h2 id="storage-disaster-recovery">Storage Disaster Recovery</h2>

<h3 id="failover-1">Failover</h3>

<p>In case of disaster recovery, create VolumeReplication CR at the Secondary Site. Since the connection to the Primary Site is lost, the operator automatically sends a GRPC request down to the driver to forcefully mark the dataSource as primary.</p>

<ul>
  <li>If you are manually recreating the PVC and PV on the secondary cluster. remove the claimRef section in the PV objects.</li>
  <li>Recreate the storageclass, PVC, and PV objects on the cluster2
    <ul>
      <li>As you are creating the static binding between PVC and PV, a new PV won’t be created here, the PVC will get bind to the existing PV.</li>
    </ul>
  </li>
  <li>Create the VolumeReplicationClass and VolumeReplication CR on the cluster2</li>
  <li>Check whether the image is primary on cluster2 by looking at toolbox or VolumeReplication CR status</li>
  <li>Once the Image is marked as Primary create the application to use the PVC
In the case of planned migration,</li>
</ul>

<h3 id="failback-1">Failback</h3>

<p>Once the failed cluster is recovered and you want to failback, follow the below steps</p>

<ul>
  <li>Update the VolumeReplication CR <code class="language-plaintext highlighter-rouge">replicationState</code> state from <code class="language-plaintext highlighter-rouge">primary</code> to <code class="language-plaintext highlighter-rouge">secondary</code> in cluster1</li>
  <li>Scale down the applications on the cluster2</li>
  <li>Update the VolumeReplication CR <code class="language-plaintext highlighter-rouge">replicationState</code> state from <code class="language-plaintext highlighter-rouge">primary</code> to <code class="language-plaintext highlighter-rouge">secondary</code> in cluster2</li>
  <li>On the cluster1 verify that the VR status is marked as volume ready to use</li>
  <li>Once the volume is marked to ready to use, change the <code class="language-plaintext highlighter-rouge">replicationState</code> state from <code class="language-plaintext highlighter-rouge">secondary</code> to <code class="language-plaintext highlighter-rouge">primary</code> in cluster1</li>
  <li>Scale up the applications again on cluster1</li>
</ul>

  </div>

  <div class="date">
    Written on May  4, 2021
  </div>
</article>


  <div id="disqus_thread"></div>
  <script>
    var disqus_config = function () {
      this.page.url = 'https://mrajanna.com/rbd-async-mirroring-dr-with-rook/';
      this.page.identifier = 'https://mrajanna.com/rbd-async-mirroring-dr-with-rook/';
    };
    (function() {
      var d = document, s = d.createElement('script');
      s.src = 'https://madhu-1-github-io-1.disqus.com/embed.js';
      s.setAttribute('data-timestamp', +new Date());
      (d.head || d.body).appendChild(s);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>



    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          
<a href="mailto:Madhupr007@gmail.com"><i class="svg-icon email"></i></a>


<a href="https://github.com/Madhu-1"><i class="svg-icon github"></i></a>

<a href="https://www.linkedin.com/in/madhu-r-4a551573"><i class="svg-icon linkedin"></i></a>


<a href="https://www.twitter.com/Madhupr007"><i class="svg-icon twitter"></i></a>



        </footer>
      </div>
    </div>

    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'qrFYIlFxt1yD_oRmFPV2ZpEOYn46EXVxnRpg2HhMaUU', 'auto');
		ga('send', 'pageview', {
		  'page': '/rbd-async-mirroring-dr-with-rook/',
		  'title': 'DR failover and failback for RBD Async mirroring with minikube'
		});
	</script>
	<!-- End Google Analytics -->


  </body>
</html>
